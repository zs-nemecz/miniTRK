{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1cafaea-2838-4612-97b2-8217c0651d47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# what we need:\n",
    "# - motion corrected runs read into arrays\n",
    "# - design matrices for each run, where\n",
    "#     - len of design matrix equals len of fMRI run\n",
    "#     - each image / image-location is a different condition\n",
    "#     - start of trial is marked with 1 in the design"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7577de9d-bb7c-4b4a-aba3-bc0d7a01766d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nibabel as nib\n",
    "import numpy as np\n",
    "import scipy\n",
    "import scipy.io as sio\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "import os\n",
    "import os.path as op\n",
    "import time\n",
    "import urllib.request\n",
    "from tqdm import tqdm # progress bars\n",
    "from pprint import pprint\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from glmsingle.glmsingle import GLM_single"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4d1c3746-a53b-4c5a-9032-779bdf1f73cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'R2thresh': 0,\n",
      " 'brainR2': [],\n",
      " 'brainexclude': False,\n",
      " 'brainthresh': [99.0, 0.1],\n",
      " 'chunklen': 50000,\n",
      " 'extra_regressors': False,\n",
      " 'fracs': array([1.  , 0.95, 0.9 , 0.85, 0.8 , 0.75, 0.7 , 0.65, 0.6 , 0.55, 0.5 ,\n",
      "       0.45, 0.4 , 0.35, 0.3 , 0.25, 0.2 , 0.15, 0.1 , 0.05]),\n",
      " 'hrffitmask': 1,\n",
      " 'hrfmodel': 'optimise',\n",
      " 'hrfthresh': 0.5,\n",
      " 'lambda': 0,\n",
      " 'n_boots': 100,\n",
      " 'n_jobs': 1,\n",
      " 'n_pcs': 10,\n",
      " 'numforhrf': 50,\n",
      " 'pcR2cutoff': [],\n",
      " 'pcR2cutoffmask': 1,\n",
      " 'pcstop': 1.05,\n",
      " 'seed': 1695742870.0499234,\n",
      " 'suppressoutput': 0,\n",
      " 'wantautoscale': 1,\n",
      " 'wantfileoutputs': [1, 0, 0, 0],\n",
      " 'wantfracridge': 0,\n",
      " 'wantglmdenoise': 0,\n",
      " 'wanthdf5': 0,\n",
      " 'wantlibrary': 0,\n",
      " 'wantlss': 0,\n",
      " 'wantmemoryoutputs': [1, 0, 0, 0],\n",
      " 'wantparametric': 0,\n",
      " 'wantpercentbold': 1}\n"
     ]
    }
   ],
   "source": [
    "# hyperparameters common to all fit models\n",
    "\n",
    "opt = dict()\n",
    "\n",
    "# set important fields for completeness (but these would be enabled by default)\n",
    "opt['wantlibrary'] = 0\n",
    "opt['wantglmdenoise'] = 0\n",
    "opt['wantfracridge'] = 0\n",
    "\n",
    "#opt['fracs'] =  np.flip(np.arange(0.5,1.0,0.05))\n",
    "\n",
    "# for the purpose of this example we will keep the relevant outputs in memory\n",
    "# and also save them to the disk\n",
    "opt['wantfileoutputs'] = [1,0,0,0]\n",
    "opt['wantmemoryoutputs'] = [1,0,0,0]\n",
    "\n",
    "# running python GLMsingle involves creating a GLM_single object\n",
    "# and then running the procedure using the .fit() routine\n",
    "glmsingle_obj = GLM_single(opt)\n",
    "\n",
    "# visualize all the hyperparameters\n",
    "pprint(glmsingle_obj.params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98037108-b9f9-448e-906a-6ac25ad6f15b",
   "metadata": {},
   "source": [
    "# First Test Subject"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "79eaa2e3-4074-41f8-9826-01003a0964b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_folder = op.join('D:\\\\', 'Zsuzsa', 'HCCCL', 'miniTRK', 'Results')\n",
    "mri_folder = op.join(base_folder, '01_MRI', 'fMRI_Preproc', 'VER3', 'aligned')\n",
    "design_folder = design_folder = op.join(base_folder, '02_APS_MRI_Logs', 'single_trials')\n",
    "subj = '351677'\n",
    "task = 'OBJ'\n",
    "acq = 'ENC'\n",
    "r = '1'\n",
    "nii_file = subj + '_' + task + '_' + acq + '_' + r + '_To_ObjEnc1MeanFunc.nii.gz'\n",
    "fname = op.join(mri_folder, nii_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c34540b0-dafc-4795-87b6-ae5c3654b324",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = nib.load(fname)\n",
    "print(img.shape)\n",
    "print(img.header)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "06ad92d5-84c7-4a24-8291-808abf8c4fe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load runs and design files\n",
    "data = []\n",
    "designs = []\n",
    "for run in ['1','2']:\n",
    "    nii_file = subj + '_' + task + '_' + acq + '_' + r + '_To_ObjEnc1MeanFunc.nii.gz'\n",
    "    fname = op.join(mri_folder, nii_file)\n",
    "    img = nib.load(fname)\n",
    "    data.append(img.get_fdata())\n",
    "    \n",
    "    design_file =  subj + '_' + task + '_SingleTrials_run_' + run + '.csv' \n",
    "    fname = op.join(design_folder, design_file)\n",
    "    design = pd.read_csv(fname).to_numpy()\n",
    "    designs.append(design)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eda3037-b4aa-4dad-8e4e-c90dec649bd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "designs[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73f5dd6e-b078-4226-aac2-fdbcbbd57560",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68030060-7a5f-48bd-9d8e-a28a6bd6e761",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot example slice from run 1\n",
    "plt.figure(figsize=(20,6))\n",
    "plt.subplot(121)\n",
    "plt.imshow(data[0][:,:,22,0])\n",
    "plt.title('example slice from run 1',fontsize=16)\n",
    "plt.subplot(122)\n",
    "plt.imshow(data[1][55,:,:,0])\n",
    "plt.title('example slice from run 2',fontsize=16)\n",
    "\n",
    "# plot design matrix from run 1\n",
    "plt.figure(figsize=(20,20))\n",
    "plt.imshow(designs[0][:,:],interpolation='none')\n",
    "plt.title('example design matrix from run 1',fontsize=16)\n",
    "plt.xlabel('conditions',fontsize=16)\n",
    "plt.ylabel('time (TR)',fontsize=16);\n",
    "\n",
    "# plot design matrix from run 2\n",
    "plt.figure(figsize=(20,20))\n",
    "plt.imshow(designs[1][:,:],interpolation='none')\n",
    "plt.title('example design matrix from run 1',fontsize=16)\n",
    "plt.xlabel('conditions',fontsize=16)\n",
    "plt.ylabel('time (TR)',fontsize=16);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5642f66-2673-4497-a753-4218498df8f4",
   "metadata": {},
   "source": [
    "# create a directory for saving GLMsingle outputs\n",
    "outputdir_glmsingle = op.join(base_folder,'01_MRI','fMRI_RSA','GLMsingle', subj, 'run1')\n",
    "\n",
    "opt = dict()\n",
    "\n",
    "# set important fields for completeness (but these would be enabled by default)\n",
    "opt['wantlibrary'] = 1\n",
    "opt['wantglmdenoise'] = 1\n",
    "opt['wantfracridge'] = 1\n",
    "\n",
    "# for the purpose of this example we will keep the relevant outputs in memory\n",
    "# and also save them to the disk\n",
    "opt['wantfileoutputs'] = [1,1,1,1]\n",
    "opt['wantmemoryoutputs'] = [1,1,1,1]\n",
    "\n",
    "# running python GLMsingle involves creating a GLM_single object\n",
    "# and then running the procedure using the .fit() routine\n",
    "glmsingle_obj = GLM_single(opt)\n",
    "\n",
    "# visualize all the hyperparameters\n",
    "pprint(glmsingle_obj.params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0765f52e-c5a1-41e5-b319-f02cb290fb34",
   "metadata": {},
   "source": [
    "start_time = time.time()\n",
    "\n",
    "if not op.exists(outputdir_glmsingle):\n",
    "\n",
    "    print(f'running GLMsingle...')\n",
    "    \n",
    "    # run GLMsingle\n",
    "    results_glmsingle = glmsingle_obj.fit(\n",
    "       designs[0],\n",
    "       data[0],\n",
    "       stimdur,\n",
    "       tr,\n",
    "       outputdir=outputdir_glmsingle)\n",
    "    \n",
    "    # we assign outputs of GLMsingle to the \"results_glmsingle\" variable.\n",
    "    # note that results_glmsingle['typea'] contains GLM estimates from an ONOFF model,\n",
    "    # where all images are treated as the same condition. these estimates\n",
    "    # could be potentially used to find cortical areas that respond to\n",
    "    # visual stimuli. we want to compare beta weights between conditions\n",
    "    # therefore we are not going to include the ONOFF betas in any analyses of \n",
    "    # voxel reliability\n",
    "    \n",
    "else:\n",
    "    print(f'loading existing GLMsingle outputs from directory:\\n\\t{outputdir_glmsingle}')\n",
    "    \n",
    "    # load existing file outputs if they exist\n",
    "    results_glmsingle = dict()\n",
    "    results_glmsingle['typea'] = np.load(op.join(outputdir_glmsingle,'TYPEA_ONOFF.npy'),allow_pickle=True).item()\n",
    "    results_glmsingle['typeb'] = np.load(op.join(outputdir_glmsingle,'TYPEB_FITHRF.npy'),allow_pickle=True).item()\n",
    "    #results_glmsingle['typec'] = np.load(op.join(outputdir_glmsingle,'TYPEC_FITHRF_GLMDENOISE.npy'),allow_pickle=True).item()\n",
    "    #results_glmsingle['typed'] = np.load(op.join(outputdir_glmsingle,'TYPED_FITHRF_GLMDENOISE_RR.npy'),allow_pickle=True).item()\n",
    "\n",
    "elapsed_time = time.time() - start_time\n",
    "\n",
    "print(\n",
    "    '\\telapsed time: ',\n",
    "    f'{time.strftime(\"%H:%M:%S\", time.gmtime(elapsed_time))}'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d6a98ab6-1071-4a51-8046-8a8dbf00d64a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running GLMsingle...\n",
      "*** FITTING TYPE-A MODEL (ONOFF) ***\n",
      "\n",
      "fitting model...\n",
      "done.\n",
      "\n",
      "preparing output...\n",
      "done.\n",
      "\n",
      "computing model fits...\n",
      "done.\n",
      "\n",
      "computing R^2...\n",
      "done.\n",
      "\n",
      "computing SNR...\n",
      "done.\n",
      "\n",
      "\n",
      "*** Saving results to D:\\Zsuzsa\\HCCCL\\miniTRK\\Results\\01_MRI\\fMRI_RSA\\GLMsingle\\351677\\TYPEA_ONOFF.npy. ***\n",
      "\n",
      "*** Setting brain R2 threshold to 0.6486648225206648 ***\n",
      "\n",
      "*** All model types done ***\n",
      "\n",
      "*** return model types in results ***\n",
      "\n",
      "\telapsed time:  00:00:58\n"
     ]
    }
   ],
   "source": [
    "# create a directory for saving GLMsingle outputs\n",
    "outputdir_glmsingle = op.join(base_folder,'01_MRI','fMRI_RSA','GLMsingle', subj)\n",
    "figuredir_glmsingle = op.join(outputdir_glmsingle, 'figures')\n",
    "\n",
    "stimdur = 3.0\n",
    "tr = 1.84\n",
    "start_time = time.time()\n",
    "\n",
    "if not op.exists(outputdir_glmsingle):\n",
    "\n",
    "    print(f'running GLMsingle...')\n",
    "    \n",
    "    # run GLMsingle\n",
    "    results_glmsingle = glmsingle_obj.fit(\n",
    "       designs,\n",
    "       data,\n",
    "       stimdur,\n",
    "       tr,\n",
    "       outputdir=outputdir_glmsingle,\n",
    "       figuredir=figuredir_glmsingle)\n",
    "    \n",
    "    # we assign outputs of GLMsingle to the \"results_glmsingle\" variable.\n",
    "    # note that results_glmsingle['typea'] contains GLM estimates from an ONOFF model,\n",
    "    # where all images are treated as the same condition. these estimates\n",
    "    # could be potentially used to find cortical areas that respond to\n",
    "    # visual stimuli. we want to compare beta weights between conditions\n",
    "    # therefore we are not going to include the ONOFF betas in any analyses of \n",
    "    # voxel reliability\n",
    "    \n",
    "else:\n",
    "    print(f'loading existing GLMsingle outputs from directory:\\n\\t{outputdir_glmsingle}')\n",
    "    \n",
    "    # load existing file outputs if they exist\n",
    "    results_glmsingle = dict()\n",
    "    results_glmsingle['typea'] = np.load(op.join(outputdir_glmsingle,'TYPEA_ONOFF.npy'),allow_pickle=True).item()\n",
    "    results_glmsingle['typeb'] = np.load(op.join(outputdir_glmsingle,'TYPEB_FITHRF.npy'),allow_pickle=True).item()\n",
    "    results_glmsingle['typec'] = np.load(op.join(outputdir_glmsingle,'TYPEC_FITHRF_GLMDENOISE.npy'),allow_pickle=True).item()\n",
    "    results_glmsingle['typed'] = np.load(op.join(outputdir_glmsingle,'TYPED_FITHRF_GLMDENOISE_RR.npy'),allow_pickle=True).item()\n",
    "\n",
    "elapsed_time = time.time() - start_time\n",
    "\n",
    "print(\n",
    "    '\\telapsed time: ',\n",
    "    f'{time.strftime(\"%H:%M:%S\", time.gmtime(elapsed_time))}'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e9eb58a2-682d-4ea5-9834-62125492b0df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[nan, nan, nan, ..., nan, nan, nan],\n",
       "        [nan, nan, nan, ..., nan, nan, nan],\n",
       "        [nan, nan, nan, ..., nan, nan, nan],\n",
       "        ...,\n",
       "        [nan, nan, nan, ..., nan, nan, nan],\n",
       "        [nan, nan, nan, ..., nan, nan, nan],\n",
       "        [nan, nan, nan, ..., nan, nan, nan]],\n",
       "\n",
       "       [[nan, nan, nan, ..., nan, nan, nan],\n",
       "        [nan, nan, nan, ..., nan, nan, nan],\n",
       "        [nan, nan, nan, ..., nan, nan, nan],\n",
       "        ...,\n",
       "        [nan, nan, nan, ..., nan, nan, nan],\n",
       "        [nan, nan, nan, ..., nan, nan, nan],\n",
       "        [nan, nan, nan, ..., nan, nan, nan]],\n",
       "\n",
       "       [[nan, nan, nan, ..., nan, nan, nan],\n",
       "        [nan, nan, nan, ..., nan, nan, nan],\n",
       "        [nan, nan, nan, ..., nan, nan, nan],\n",
       "        ...,\n",
       "        [nan, nan, nan, ..., nan, nan, nan],\n",
       "        [nan, nan, nan, ..., nan, nan, nan],\n",
       "        [nan, nan, nan, ..., nan, nan, nan]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[nan, nan, nan, ..., nan, nan, nan],\n",
       "        [nan, nan, nan, ..., nan, nan, nan],\n",
       "        [nan, nan, nan, ..., nan, nan, nan],\n",
       "        ...,\n",
       "        [nan, nan, nan, ..., nan, nan, nan],\n",
       "        [nan, nan, nan, ..., nan, nan, nan],\n",
       "        [nan, nan, nan, ..., nan, nan, nan]],\n",
       "\n",
       "       [[nan, nan, nan, ..., nan, nan, nan],\n",
       "        [nan, nan, nan, ..., nan, nan, nan],\n",
       "        [nan, nan, nan, ..., nan, nan, nan],\n",
       "        ...,\n",
       "        [nan, nan, nan, ..., nan, nan, nan],\n",
       "        [nan, nan, nan, ..., nan, nan, nan],\n",
       "        [nan, nan, nan, ..., nan, nan, nan]],\n",
       "\n",
       "       [[nan, nan, nan, ..., nan, nan, nan],\n",
       "        [nan, nan, nan, ..., nan, nan, nan],\n",
       "        [nan, nan, nan, ..., nan, nan, nan],\n",
       "        ...,\n",
       "        [nan, nan, nan, ..., nan, nan, nan],\n",
       "        [nan, nan, nan, ..., nan, nan, nan],\n",
       "        [nan, nan, nan, ..., nan, nan, nan]]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_glmsingle['typea']['onoffR2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "158d98b1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "131bab93-d523-4152-b9b1-7be606b69512",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_glmsingle['typed']['R2'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1ef298a-287c-40dc-b8d4-74b982178491",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we are going to plot several outputs from the FIT_HRF_GLMdenoise_RR GLM,\n",
    "# which contains the full set of GLMsingle optimizations.\n",
    "\n",
    "# we will plot betas, R2, optimal HRF indices, and the voxel frac values\n",
    "plot_fields = ['betasmd','R2','HRFindex','FRACvalue']\n",
    "colormaps = ['RdBu_r','hot','jet','copper']\n",
    "clims = [[-5,5],[0,85],[0,20],[0,1]]\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "\n",
    "for i in range(len(plot_fields)):\n",
    "    \n",
    "    plt.subplot(2,2,i+1)\n",
    "    \n",
    "    if i == 0:\n",
    "        # when plotting betas, for simplicity just average across all image presentations\n",
    "        # this will yield a summary of whether voxels tend to increase or decrease their \n",
    "        # activity in response to the experimental stimuli (similar to outputs from \n",
    "        # an ONOFF GLM)\n",
    "        plot_data = np.nanmean(results_glmsingle['typed'][plot_fields[i]].reshape(136,136,80,152),3)[55,:,:].T\n",
    "        print(plot_data.shape)\n",
    "        titlestr = 'average GLM betas'\n",
    "    \n",
    "    else:\n",
    "        # plot all other voxel-wise metrics as outputted from GLMsingle\n",
    "        plot_data = results_glmsingle['typed'][plot_fields[i]].reshape(136,136,80)[55,:,:].T\n",
    "        titlestr = plot_fields[i]\n",
    "    \n",
    "    plt.imshow(plot_data,cmap=colormaps[i],clim=clims[i], origin=\"lower\")\n",
    "    plt.colorbar()\n",
    "    plt.title(titlestr)\n",
    "    plt.axis(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "547d99cb-0379-43ff-8b83-84fc3d547060",
   "metadata": {},
   "outputs": [],
   "source": [
    "slices = results_glmsingle['typed']['betasmd'].shape[2]\n",
    "mean_betas=np.nanmean(results_glmsingle['typed']['betasmd'],3)\n",
    "fi, axs = plt.subplots(int(slices/4), 4, sharex=True, sharey=True, figsize=(8,32), layout='constrained')\n",
    "rows = range(int(slices/4))\n",
    "cols = range(4)\n",
    "s = 0\n",
    "for r in rows:\n",
    "    for c in cols:\n",
    "        axs[r][c].imshow(mean_betas[:,:,s], cmap='RdBu_r', clim=[-5,5])\n",
    "        axs[r][c].set_title(str(s))\n",
    "        s += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b6fb653-f512-46a3-8fb7-0416c4b272de",
   "metadata": {},
   "outputs": [],
   "source": [
    "end = results_glmsingle['typed']['betasmd'].shape[1]\n",
    "slices = np.arange(9,end-9,3)\n",
    "rows = range(int(len(slices)/3))\n",
    "cols = range(3)\n",
    "mean_betas=np.nanmean(results_glmsingle['typed']['betasmd'],3)\n",
    "fi, axs = plt.subplots(len(rows), 3, sharex=True, sharey=True, figsize=(8,32), layout='constrained')\n",
    "\n",
    "s = 0\n",
    "for r in rows:\n",
    "    for c in cols:\n",
    "        axs[r][c].imshow(mean_betas[:,slices[s],:], cmap='RdBu_r', clim=[-5,5])\n",
    "        axs[r][c].set_title(str(slices[s]))\n",
    "        s += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c94e3b4-e786-4c96-9f49-b883aa110e7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "end = results_glmsingle['typed']['betasmd'].shape[1]\n",
    "slices = np.arange(18,end-18,2)\n",
    "rows = range(int(len(slices)/2))\n",
    "cols = range(3)\n",
    "mean_betas=np.nanmean(results_glmsingle['typed']['betasmd'],3)\n",
    "fi, axs = plt.subplots(len(rows), 3, sharex=True, sharey=True, figsize=(8,32), layout='constrained')\n",
    "\n",
    "s = 0\n",
    "for r in rows:\n",
    "    for c in cols:\n",
    "        axs[r][c].imshow(mean_betas[slices[s],:,:], cmap='RdBu_r', clim=[-5,5])\n",
    "        axs[r][c].set_title(str(slices[s]))\n",
    "        s += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c1f8bb9-33fb-4e32-94f5-85681314d0be",
   "metadata": {},
   "source": [
    "slices = results_glmsingle['typea']['betasmd'].shape[2]\n",
    "fi, axs = plt.subplots(int(slices/4), 4, sharex=True, sharey=True, figsize=(8,32), layout='constrained')\n",
    "rows = range(int(slices/4))\n",
    "cols = range(4)\n",
    "s = 0\n",
    "for r in rows:\n",
    "    for c in cols:\n",
    "        axs[r][c].imshow(results_glmsingle['typea']['betasmd'][:,:,s], cmap='RdBu_r', clim=[-5,5])\n",
    "        axs[r][c].set_title(str(s))\n",
    "        s += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10011efb-70c7-4e1c-abc2-295fed252b60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# consolidate design matrices\n",
    "designALL = np.concatenate(designs,axis=0)\n",
    "\n",
    "# construct a vector containing 0-indexed condition numbers in chronological order\n",
    "corder = []\n",
    "for p in range(designALL.shape[0]):\n",
    "    if np.any(designALL[p]):\n",
    "        corder.append(np.argwhere(designALL[p])[0,0])\n",
    "        \n",
    "corder = np.array(corder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4bddb4e-649d-4832-b526-303adde85db4",
   "metadata": {},
   "outputs": [],
   "source": [
    "designALL.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5fc714f-3817-4083-ba11-db2a101718ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "corder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0edfd59b-94ff-4f2c-b04f-974bd731f9fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "corder.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6ea5336-8604-4f8c-b8df-77fd31c29fa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# in order to compute split-half reliability, we have to do some indexing.\n",
    "# we want to find images with least two repetitions and then prepare a\n",
    "# useful matrix of indices that refer to when these occur.\n",
    "\n",
    "repindices = [] # 2 x images containing stimulus trial indices.\n",
    "\n",
    "# the first row refers to the first presentation; the second row refers to\n",
    "# the second presentation.\n",
    "for p in range(designALL.shape[1]): # loop over every condition\n",
    "    \n",
    "    temp = np.argwhere(corder==p)[:,0] # find indices where this condition was shown\n",
    "    \n",
    "    # note that for conditions with 3 presentations, we are simply ignoring the third trial\n",
    "    if len(temp) >= 2:\n",
    "        repindices.append([temp[0], temp[1]]) \n",
    "\n",
    "repindices = np.vstack(np.array(repindices)).T \n",
    "repindices.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a375b4f-071e-4d84-8213-f4ba8adf15e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "repindices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05d03331-d84f-4ea4-8031-8b52988c4a16",
   "metadata": {},
   "outputs": [],
   "source": [
    "corder[126]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf327269-fb56-4231-b193-ba36f5debaa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read mask image\n",
    "\n",
    "mask_folder = op.join(base_folder, '01_MRI', 'ANTS_REG', 'ROIS', subj)\n",
    "mask_file = 'C-mask_' + subj + '_right_CA3DG-To-meanFunc.nii.gz'\n",
    "fname = op.join(mask_folder, mask_file)\n",
    "img = nib.load(fname)\n",
    "roi = img.get_fdata()\n",
    "\n",
    "r_ca3dg = roi.astype(float)\n",
    "\n",
    "# convert voxels outside ROI to nan for overlay plotting\n",
    "r_ca3dg[r_ca3dg==0] = np.nan \n",
    "\n",
    "# get mean fMRI volume from run 1\n",
    "xyzt = (136,136,80,250)\n",
    "print(xyzt)\n",
    "meanvol = np.mean(data[0].reshape(xyzt),axis=3)\n",
    "\n",
    "# plot ROI on top of overlay\n",
    "plt.figure(figsize=(12,6))\n",
    "plt.imshow(meanvol[:,63,:],cmap='gray')\n",
    "plt.imshow(r_ca3dg[:,63,:],cmap='Blues',clim=(0,2))\n",
    "\n",
    "plt.title('voxels in nsdgeneral ROI')\n",
    "plt.box(False)\n",
    "plt.axis(False);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3781eb07-8926-4e60-ba0c-d6e3e5f60ccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read mask image\n",
    "mask_file = 'C-mask_' + subj + '_right_PRC-To-meanFunc.nii.gz'\n",
    "fname = op.join(mask_folder, mask_file)\n",
    "img = nib.load(fname)\n",
    "roi = img.get_fdata()\n",
    "\n",
    "r_prc = roi.astype(float)\n",
    "\n",
    "# convert voxels outside ROI to nan for overlay plotting\n",
    "r_prc[r_prc==0] = np.nan \n",
    "\n",
    "# get mean fMRI volume from run 1\n",
    "xyzt = (136,136,80,250)\n",
    "print(xyzt)\n",
    "meanvol = np.mean(data[0].reshape(xyzt),axis=3)\n",
    "\n",
    "# plot ROI on top of overlay\n",
    "plt.figure(figsize=(12,6))\n",
    "plt.imshow(meanvol[:,70,:],cmap='gray')\n",
    "plt.imshow(r_prc[:,70,:],cmap='Blues',clim=(0,2))\n",
    "\n",
    "plt.title('voxels in nsdgeneral ROI')\n",
    "plt.box(False)\n",
    "plt.axis(False);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3b51d95-2f94-4060-a271-e74306f7ed1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dictionary containing the GLM betas from the four different models we will compare.\n",
    "# note that the \"assume hrf\" betas come from the \"typeb\" field of our baseline GLM\n",
    "# (with HRF fitting turned off), and that the \"fit hrf\" betas also come from \n",
    "# the \"typeb\" field of the GLM that ran with all default GLMsingle routines\n",
    "# enabled\n",
    "\n",
    "models = dict()\n",
    "models['fithrf'] = results_glmsingle['typeb']['betasmd'].reshape(136,136,80,152)\n",
    "models['fithrf_glmdenoise'] = results_glmsingle['typec']['betasmd'].reshape(136,136,80,152)\n",
    "models['fithrf_glmdenoise_rr'] = results_glmsingle['typed']['betasmd'].reshape(136,136,80,152)\n",
    "\n",
    "# finally, let's compute split-half reliability. we are going to loop\n",
    "# through our 4 models and calculate split-half reliability for each of them\n",
    "\n",
    "vox_reliabilities = [] # output variable for reliability values\n",
    "\n",
    "modelnames = list(models.keys())\n",
    "\n",
    "# for each beta version...\n",
    "for m in range(len(modelnames)):\n",
    "    \n",
    "    print(f'computing reliability for beta version: {modelnames[m]}')\n",
    "    time.sleep(1)\n",
    "    \n",
    "    # get the repeated-condition GLM betas using our repindices variable\n",
    "    betas = models[modelnames[m]][:,:,:,repindices] # automatically reshapes to (X x Y x Z x 2 x nConditions)\n",
    "    x,y,z = betas.shape[:3] \n",
    "    \n",
    "    rels = np.full((x,y,z),np.nan)\n",
    "    \n",
    "    # loop through voxels in the 3D volume...\n",
    "    for xx in tqdm(range(x)):\n",
    "        for yy in range(y):\n",
    "            for zz in range(z):\n",
    "                \n",
    "                # reliability at a given voxel is pearson correlation between response profiles from first and \n",
    "                # second image presentations (dim = 25 repeated conditions)\n",
    "                rels[xx,yy,zz] = np.corrcoef(betas[xx,yy,zz,0],\n",
    "                                             betas[xx,yy,zz,1])[1,0]\n",
    "          \n",
    "    vox_reliabilities.append(rels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ca2f07e-c32d-411d-8e5b-5d1063b7f654",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for each GLM we will calculate median reliability for voxels within the\n",
    "# nsdgeneral visual ROI and compare using a bar graph\n",
    "\n",
    "comparison = []\n",
    "for vr in vox_reliabilities:\n",
    "    comparison.append(np.nanmedian(vr[r_ca3dg==1]))\n",
    "\n",
    "plt.figure(figsize=(18,6))\n",
    "plt.subplot(121)\n",
    "plt.bar(np.arange(len(comparison)),comparison,width=0.5)\n",
    "plt.title('Median voxel split-half reliability of GLM models')\n",
    "plt.xticks(np.arange(len(comparison)),np.array(['FITHRF', 'FITHRF\\nGLMDENOISE', 'FITHRF\\nGLMDENOISE\\nRR']));\n",
    "plt.ylim([-0.1,0.2])\n",
    "\n",
    "# draw plot showing the change in reliability between the baseline GLM\n",
    "# and the final output of GLMsingle (fithrf-glmdenoise-RR betas)\n",
    "vox_improvement = np.squeeze(vox_reliabilities[-1] - vox_reliabilities[0])\n",
    "vox_improvement[r_ca3dg != 1] = np.nan\n",
    "\n",
    "plt.subplot(122)\n",
    "plt.imshow(meanvol[:,:,32],cmap='gray',aspect='auto')\n",
    "plt.imshow(vox_improvement[:,:,32],cmap='RdBu_r',clim=(-0.3,0.3),aspect='auto')\n",
    "plt.colorbar()\n",
    "plt.title('change in nsdgeneral voxel reliability**\\ndue to GLMsingle (r)')\n",
    "plt.xticks([])\n",
    "plt.yticks([])\n",
    "plt.xlabel('\\n**plotting (FITHRF_GLMDENOISE_RR - ASSUMEHRF) reliabilities');\n",
    "\n",
    "# notice that there is systematic increase in reliability moving from the\n",
    "# first to the second to the third to the final fourth version of the GLM\n",
    "# results. these increases reflect, respectively, the addition of HRF\n",
    "# fitting, the derivation and use of data-driven nuisance regressors, and\n",
    "# the use of ridge regression as a way to regularize the instability of\n",
    "# closely spaced experimental trials. depending on one's experimental\n",
    "# goals, it is possible with setting of option flags to activate a subset\n",
    "# of these analysis features.\n",
    "\n",
    "# also, keep in mind that in the above figure, we are simply showing the\n",
    "# median as a metric of the central tendency (you may want to peruse\n",
    "# individual voxels in scatter plots, for example)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb19fd4e-0aa9-4b59-8be5-e6a3ed06e2dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for each GLM we will calculate median reliability for voxels within the\n",
    "# nsdgeneral visual ROI and compare using a bar graph\n",
    "\n",
    "comparison = []\n",
    "for vr in vox_reliabilities:\n",
    "    comparison.append(np.nanmedian(vr[r_prc==1]))\n",
    "   \n",
    "\n",
    "plt.figure(figsize=(18,6))\n",
    "plt.subplot(121)\n",
    "plt.bar(np.arange(len(comparison)),comparison,width=0.5)\n",
    "plt.title('Median voxel split-half reliability of GLM models')\n",
    "plt.xticks(np.arange(len(comparison)),np.array(['FITHRF', 'FITHRF\\nGLMDENOISE', 'FITHRF\\nGLMDENOISE\\nRR']));\n",
    "plt.ylim([-0.1,0.2])\n",
    "\n",
    "# draw plot showing the change in reliability between the baseline GLM\n",
    "# and the final output of GLMsingle (fithrf-glmdenoise-RR betas)\n",
    "vox_improvement = np.squeeze(vox_reliabilities[-1] - vox_reliabilities[0])\n",
    "vox_improvement[r_prc != 1] = np.nan\n",
    "\n",
    "plt.subplot(122)\n",
    "plt.imshow(meanvol[:,:,26],cmap='gray',aspect='auto')\n",
    "plt.imshow(vox_improvement[:,:,26],cmap='RdBu_r',clim=(-0.3,0.3),aspect='auto')\n",
    "plt.colorbar()\n",
    "plt.title('change in nsdgeneral voxel reliability**\\ndue to GLMsingle (r)')\n",
    "plt.xticks([])\n",
    "plt.yticks([])\n",
    "plt.xlabel('\\n**plotting (FITHRF_GLMDENOISE_RR - ASSUMEHRF) reliabilities');\n",
    "\n",
    "# notice that there is systematic increase in reliability moving from the\n",
    "# first to the second to the third to the final fourth version of the GLM\n",
    "# results. these increases reflect, respectively, the addition of HRF\n",
    "# fitting, the derivation and use of data-driven nuisance regressors, and\n",
    "# the use of ridge regression as a way to regularize the instability of\n",
    "# closely spaced experimental trials. depending on one's experimental\n",
    "# goals, it is possible with setting of option flags to activate a subset\n",
    "# of these analysis features.\n",
    "\n",
    "# also, keep in mind that in the above figure, we are simply showing the\n",
    "# median as a metric of the central tendency (you may want to peruse\n",
    "# individual voxels in scatter plots, for example)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b84a2c0e-9503-48ac-bce3-97d96b7bb67e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for each GLM we will calculate median reliability for voxels within the\n",
    "# nsdgeneral visual ROI and compare using a bar graph\n",
    "\n",
    "comparison = []\n",
    "for vr in vox_reliabilities:\n",
    "    comparison.append(np.nanmedian(vr))\n",
    "   \n",
    "\n",
    "plt.figure(figsize=(12,4))\n",
    "plt.subplot(121)\n",
    "plt.bar(np.arange(len(comparison)),comparison,width=0.5)\n",
    "plt.title('Median voxel split-half reliability of GLM models')\n",
    "plt.xticks(np.arange(len(comparison)),np.array(['FITHRF', 'FITHRF\\nGLMDENOISE', 'FITHRF\\nGLMDENOISE\\nRR']));\n",
    "plt.ylim([-0.1,0.2])\n",
    "\n",
    "# draw plot showing the change in reliability between the baseline GLM\n",
    "# and the final output of GLMsingle (fithrf-glmdenoise-RR betas)\n",
    "vox_improvement = np.squeeze(vox_reliabilities[-1] - vox_reliabilities[0])\n",
    "#vox_improvement[r_prc != 1] = np.nan\n",
    "\n",
    "plt.subplot(122)\n",
    "plt.imshow(meanvol[:,:,24],cmap='gray',aspect='auto')\n",
    "plt.imshow(vox_improvement[:,:,24],cmap='RdBu_r',clim=(-0.3,0.3),aspect='auto')\n",
    "plt.colorbar()\n",
    "plt.title('change in nsdgeneral voxel reliability**\\ndue to GLMsingle (r)')\n",
    "plt.xticks([])\n",
    "plt.yticks([])\n",
    "plt.xlabel('\\n**plotting (FITHRF_GLMDENOISE_RR - ASSUMEHRF) reliabilities');\n",
    "\n",
    "# notice that there is systematic increase in reliability moving from the\n",
    "# first to the second to the third to the final fourth version of the GLM\n",
    "# results. these increases reflect, respectively, the addition of HRF\n",
    "# fitting, the derivation and use of data-driven nuisance regressors, and\n",
    "# the use of ridge regression as a way to regularize the instability of\n",
    "# closely spaced experimental trials. depending on one's experimental\n",
    "# goals, it is possible with setting of option flags to activate a subset\n",
    "# of these analysis features.\n",
    "\n",
    "# also, keep in mind that in the above figure, we are simply showing the\n",
    "# median as a metric of the central tendency (you may want to peruse\n",
    "# individual voxels in scatter plots, for example)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ce36db6-12d5-4e14-9da7-67239dddd362",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(18,6))\n",
    "plt.subplot(131)\n",
    "plt.imshow(vox_reliabilities[0][:,:,24],cmap='RdBu_r',clim=(-0.3,0.3),aspect='auto', vmin=-0.4,vmax=0.4)\n",
    "plt.title('Voxel reliabilities with FITHRF', fontsize=10)\n",
    "plt.subplot(132)\n",
    "plt.imshow(vox_reliabilities[1][:,:,24],cmap='RdBu_r',clim=(-0.3,0.3),aspect='auto', vmin=-0.4,vmax=0.4)\n",
    "plt.title('Voxel reliabilities with FITHRF_GLMDENOISE', fontsize=10)\n",
    "plt.subplot(133)\n",
    "plt.imshow(vox_reliabilities[2][:,:,24],cmap='RdBu_r',clim=(-0.3,0.3),aspect='auto', vmin=-0.4,vmax=0.4)\n",
    "plt.title('Voxel reliabilities with FITHRF_GLMDENOISE_RR', fontsize=10)\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07227cc9-34d1-417b-b5bc-2928e333c81f",
   "metadata": {},
   "outputs": [],
   "source": [
    "comparison[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68374b9b-e856-4629-a769-7b9cbbb30cc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6,3))\n",
    "plt.hist(vox_reliabilities[0].reshape(-1),25,alpha=0.8,color='tomato');\n",
    "plt.hist(vox_reliabilities[1].reshape(-1),25,alpha=0.6,color='dodgerblue');\n",
    "plt.hist(vox_reliabilities[2].reshape(-1),25,alpha=0.6,color='limegreen');\n",
    "plt.xlabel('reliability (r)')\n",
    "plt.ylabel('# voxels')\n",
    "plt.legend(['FITHRF', 'FITHRF_GLMDENOISE', 'FITHRF_GLMDENOISE_RR'], fontsize=8)\n",
    "plt.title('Change in distribution of voxel reliabilities');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11327e76-6191-4864-af7e-413a341b7ff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# further todos for RSA\n",
    "\n",
    "# read all roi masks\n",
    "# calculate correlation between all erp pairs and lure pairs and out-of triplet random image (and compare between ROIs)\n",
    "\n",
    "# create correlation matrix between all images (some images may never be shown to subject during encoding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "852c287c-4784-4bbd-8267-b8e2cb372e13",
   "metadata": {},
   "outputs": [],
   "source": [
    "images = [str(j+1) + k for j in range(181) for k in 'abc']\n",
    "designALL.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "193a74f4-f90b-4abe-be40-eb65eff133b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# in order to compute split-half reliability, we have to do some indexing.\n",
    "# we want to find images with least two repetitions and then prepare a\n",
    "# useful matrix of indices that refer to when these occur.\n",
    "\n",
    "lureindices = [] # 2 x images containing stimulus trial indices.\n",
    "lures = []\n",
    "\n",
    "# the first row refers to the first presentation; the second row refers to\n",
    "# the second presentation.\n",
    "for i, im in enumerate(images): # loop over every condition\n",
    "    temp = []\n",
    "    \n",
    "    temp = np.argwhere(corder==i)[:,0] # find indices where this condition was shown\n",
    "    \n",
    "    if len(temp) == 1: # check if this exact image was shown only once (otherwise it's a repeat)\n",
    "        image_version = im[-1]\n",
    "               \n",
    "        lureindices.append(temp[0])\n",
    "        lures.append(im)\n",
    "\n",
    "lureindices = np.array(lureindices).reshape(48,2).T\n",
    "lures = np.array(lures).reshape(48,2).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f7e4169-a1d1-44d9-a3a8-22c24e17b3e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "lureindices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72a6d8c4-38a4-4c0f-815c-d74459616b3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "r_ca3dg_betas = models['fithrf_glmdenoise'][r_ca3dg==1, :].T\n",
    "r_prc_betas = models['fithrf_glmdenoise'][r_prc==1, :].T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b6b4b44-45ca-483b-8830-a8a97257aa16",
   "metadata": {},
   "outputs": [],
   "source": [
    "r_ca3dg_corr = np.corrcoef(r_ca3dg_betas)\n",
    "r_prc_corr = np.corrcoef(r_prc_betas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0130791b-098f-4b2f-8828-bbb39131f4e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(r_ca3dg_corr, vmin=-1, vmax=1, cmap='bwr')\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be10f742-c93a-469a-9475-7c83f4b16c25",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(r_prc_corr, vmin=-1, vmax=1, cmap='bwr')\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f42fb0f-1ecd-4632-bf98-844c4854f9b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(r_ca3dg_corr[76:,:76], vmin=-1, vmax=1, cmap='bwr')\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97b26edc-ce89-40d5-a436-f7db64096ce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "r_ca3dg_lures = r_ca3dg_corr[lureindices[0], lureindices[1]]\n",
    "r_prc_lures = r_prc_corr[lureindices[0], lureindices[1]]\n",
    "\n",
    "r_ca3dg_reps = r_ca3dg_corr[repindices[0], repindices[1]]\n",
    "r_prc_reps = r_prc_corr[repindices[0], repindices[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fd3c505-f956-4f1f-a11b-575ed981f00c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(r_ca3dg_lures)\n",
    "print(r_ca3dg_corr[117,123])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60bc140d-f701-4e10-b5bc-a1ba81027206",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(r_ca3dg_lures, alpha=0.6,color='tomato');\n",
    "plt.hist(r_ca3dg_reps, alpha=0.6, color='limegreen');\n",
    "plt.xlabel('pattern similarity in R CA3DG')\n",
    "plt.ylabel('# conditions')\n",
    "plt.legend(['lures', 'repetitions'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c068d98c-805f-4609-9ba0-c8d4530cf56a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(r_prc_lures, alpha=0.6,color='tomato');\n",
    "plt.hist(r_prc_reps, alpha=0.6, color='limegreen');\n",
    "plt.xlabel('pattern similarity in R PRC')\n",
    "plt.ylabel('# conditions')\n",
    "plt.legend(['lures', 'repetitions'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "786f3050-8a30-49af-be04-0de99503966f",
   "metadata": {},
   "outputs": [],
   "source": [
    "comparison = []\n",
    "for c in [r_prc_lures, r_prc_reps]:\n",
    "    comparison.append(np.nanmedian(c))\n",
    "\n",
    "plt.bar(np.arange(len(comparison)),comparison,width=0.5)\n",
    "plt.title('Median voxel pattern similarity')\n",
    "plt.xticks(np.arange(len(comparison)),np.array(['Lures', 'Reps']));\n",
    "plt.ylim([0.0,0.2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f84a10a7-a85a-405d-9bbb-29ffbb4f2b3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "comparison = []\n",
    "for c in [r_ca3dg_lures, r_ca3dg_reps]:\n",
    "    comparison.append(np.nanmedian(c))\n",
    "\n",
    "plt.bar(np.arange(len(comparison)),comparison,width=0.5)\n",
    "plt.title('Median voxel pattern similarity')\n",
    "plt.xticks(np.arange(len(comparison)),np.array(['Lures', 'Reps']));\n",
    "plt.ylim([0.0,0.2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f2dd5c4-3f80-4912-96bb-af1e1989eef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO - correlate Lure 1s with Rep 2s (as foil relationship)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd242a7c-fc7e-454f-8062-b212195a0bd1",
   "metadata": {},
   "source": [
    "# Second Test Subject"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3c2d9f5-0925-491d-b4d8-3b4bf1d14244",
   "metadata": {},
   "outputs": [],
   "source": [
    "subj = '760384'\n",
    "\n",
    "# load runs and design files\n",
    "data = []\n",
    "designs = []\n",
    "for run in ['1','2']:\n",
    "    nii_file = subj + '_' + task + '_' + acq + '_' + r + '_To_ObjEnc1MeanFunc.nii.gz'\n",
    "    fname = op.join(mri_folder, nii_file)\n",
    "    img = nib.load(fname)\n",
    "    data.append(img.get_fdata())\n",
    "    \n",
    "    design_file =  subj + '_' + task + '_SingleTrials_run_' + run + '.csv' \n",
    "    fname = op.join(design_folder, design_file)\n",
    "    design = pd.read_csv(fname).to_numpy()\n",
    "    designs.append(design)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beef71d4-35fe-407f-a4f3-f5a11a10156f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('design shape: ', designs[0].shape)\n",
    "print('data shape: ', data[0].shape)\n",
    "# plot example slice from run 1\n",
    "plt.figure(figsize=(20,6))\n",
    "plt.subplot(121)\n",
    "plt.imshow(data[0][:,:,27,0])\n",
    "plt.title('example slice from run 1',fontsize=16)\n",
    "plt.subplot(122)\n",
    "plt.imshow(data[1][55,:,:,0])\n",
    "plt.title('example slice from run 2',fontsize=16)\n",
    "\n",
    "# plot design matrix from run 1\n",
    "plt.figure(figsize=(20,20))\n",
    "plt.imshow(designs[0][:,:],interpolation='none')\n",
    "plt.title('example design matrix from run 1',fontsize=16)\n",
    "plt.xlabel('conditions',fontsize=16)\n",
    "plt.ylabel('time (TR)',fontsize=16);\n",
    "\n",
    "# plot design matrix from run 2\n",
    "plt.figure(figsize=(20,20))\n",
    "plt.imshow(designs[1][:,:],interpolation='none')\n",
    "plt.title('example design matrix from run 2',fontsize=16)\n",
    "plt.xlabel('conditions',fontsize=16)\n",
    "plt.ylabel('time (TR)',fontsize=16);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40b159b2-82e3-4cb8-b0d4-79d6640dac9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a directory for saving GLMsingle outputs\n",
    "outputdir_glmsingle = op.join('..', '..', 'Results','01_MRI','fMRI_RSA','GLMsingle', subj, 'aligned')\n",
    "\n",
    "stimdur = 3.0\n",
    "tr = 1.84\n",
    "start_time = time.time()\n",
    "\n",
    "if not op.exists(outputdir_glmsingle):\n",
    "\n",
    "    print(f'running GLMsingle...')\n",
    "    \n",
    "    # run GLMsingle\n",
    "    results_glmsingle = glmsingle_obj.fit(\n",
    "       designs,\n",
    "       data,\n",
    "       stimdur,\n",
    "       tr,\n",
    "       outputdir=outputdir_glmsingle)\n",
    "    \n",
    "    # we assign outputs of GLMsingle to the \"results_glmsingle\" variable.\n",
    "    # note that results_glmsingle['typea'] contains GLM estimates from an ONOFF model,\n",
    "    # where all images are treated as the same condition. these estimates\n",
    "    # could be potentially used to find cortical areas that respond to\n",
    "    # visual stimuli. we want to compare beta weights between conditions\n",
    "    # therefore we are not going to include the ONOFF betas in any analyses of \n",
    "    # voxel reliability\n",
    "    \n",
    "else:\n",
    "    print(f'loading existing GLMsingle outputs from directory:\\n\\t{outputdir_glmsingle}')\n",
    "    \n",
    "    # load existing file outputs if they exist\n",
    "    results_glmsingle = dict()\n",
    "    results_glmsingle['typea'] = np.load(op.join(outputdir_glmsingle,'TYPEA_ONOFF.npy'),allow_pickle=True).item()\n",
    "    results_glmsingle['typeb'] = np.load(op.join(outputdir_glmsingle,'TYPEB_FITHRF.npy'),allow_pickle=True).item()\n",
    "    results_glmsingle['typec'] = np.load(op.join(outputdir_glmsingle,'TYPEC_FITHRF_GLMDENOISE.npy'),allow_pickle=True).item()\n",
    "    results_glmsingle['typed'] = np.load(op.join(outputdir_glmsingle,'TYPED_FITHRF_GLMDENOISE_RR.npy'),allow_pickle=True).item()\n",
    "\n",
    "elapsed_time = time.time() - start_time\n",
    "\n",
    "print(\n",
    "    '\\telapsed time: ',\n",
    "    f'{time.strftime(\"%H:%M:%S\", time.gmtime(elapsed_time))}'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18526ef2-214a-49fc-8da2-80a68c2754b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we are going to plot several outputs from the FIT_HRF_GLMdenoise_RR GLM,\n",
    "# which contains the full set of GLMsingle optimizations.\n",
    "\n",
    "# we will plot betas, R2, optimal HRF indices, and the voxel frac values\n",
    "plot_fields = ['betasmd','R2','HRFindex','FRACvalue']\n",
    "colormaps = ['RdBu_r','hot','jet','copper']\n",
    "clims = [[-5,5],[0,85],[0,20],[0,1]]\n",
    "\n",
    "plt.figure(figsize=(12,8))\n",
    "\n",
    "for i in range(len(plot_fields)):\n",
    "    \n",
    "    plt.subplot(2,2,i+1)\n",
    "    \n",
    "    if i == 0:\n",
    "        # when plotting betas, for simplicity just average across all image presentations\n",
    "        # this will yield a summary of whether voxels tend to increase or decrease their \n",
    "        # activity in response to the experimental stimuli (similar to outputs from \n",
    "        # an ONOFF GLM)\n",
    "        plot_data = np.nanmean(results_glmsingle['typed'][plot_fields[i]].reshape(136,136,80,152),3)[:,:,8]\n",
    "        print(plot_data.shape)\n",
    "        titlestr = 'average GLM betas'\n",
    "    \n",
    "    else:\n",
    "        # plot all other voxel-wise metrics as outputted from GLMsingle\n",
    "        plot_data = results_glmsingle['typed'][plot_fields[i]].reshape(136,136,80)[:,:,8]\n",
    "        titlestr = plot_fields[i]\n",
    "    \n",
    "    plt.imshow(plot_data,cmap=colormaps[i],clim=clims[i])\n",
    "    plt.colorbar()\n",
    "    plt.title(titlestr)\n",
    "    plt.axis(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a111dcbf-d843-4ee4-bdfc-c72878767896",
   "metadata": {},
   "outputs": [],
   "source": [
    "slices = results_glmsingle['typed']['betasmd'].shape[2]\n",
    "mean_betas=np.nanmean(results_glmsingle['typed']['betasmd'],3)\n",
    "fi, axs = plt.subplots(int(slices/4), 4, sharex=True, sharey=True, figsize=(8,32), layout='constrained')\n",
    "rows = range(int(slices/4))\n",
    "cols = range(4)\n",
    "s = 0\n",
    "for r in rows:\n",
    "    for c in cols:\n",
    "        axs[r][c].imshow(mean_betas[:,:,s], cmap='RdBu_r', clim=[-5,5])\n",
    "        axs[r][c].set_title(str(s))\n",
    "        s += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5cbf8c6-64f7-409f-ad5a-5b1f50130220",
   "metadata": {},
   "outputs": [],
   "source": [
    "# consolidate design matrices\n",
    "designALL = np.concatenate(designs,axis=0)\n",
    "\n",
    "# construct a vector containing 0-indexed condition numbers in chronological order\n",
    "corder = []\n",
    "for p in range(designALL.shape[0]):\n",
    "    if np.any(designALL[p]):\n",
    "        corder.append(np.argwhere(designALL[p])[0,0])\n",
    "        \n",
    "corder = np.array(corder)\n",
    "\n",
    "# in order to compute split-half reliability, we have to do some indexing.\n",
    "# we want to find images with least two repetitions and then prepare a\n",
    "# useful matrix of indices that refer to when these occur.\n",
    "\n",
    "repindices = [] # 2 x images containing stimulus trial indices.\n",
    "\n",
    "# the first row refers to the first presentation; the second row refers to\n",
    "# the second presentation.\n",
    "for p in range(designALL.shape[1]): # loop over every condition\n",
    "    \n",
    "    temp = np.argwhere(corder==p)[:,0] # find indices where this condition was shown\n",
    "    \n",
    "    # note that for conditions with 3 presentations, we are simply ignoring the third trial\n",
    "    if len(temp) >= 2:\n",
    "        repindices.append([temp[0], temp[1]]) \n",
    "\n",
    "repindices = np.vstack(np.array(repindices)).T \n",
    "repindices.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b29e58c1-d6f3-4320-b654-598704ac70c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dictionary containing the GLM betas from the four different models we will compare.\n",
    "# note that the \"assume hrf\" betas come from the \"typeb\" field of our baseline GLM\n",
    "# (with HRF fitting turned off), and that the \"fit hrf\" betas also come from \n",
    "# the \"typeb\" field of the GLM that ran with all default GLMsingle routines\n",
    "# enabled\n",
    "\n",
    "models = dict()\n",
    "models['fithrf'] = results_glmsingle['typeb']['betasmd'].reshape(136,136,80,152)\n",
    "models['fithrf_glmdenoise'] = results_glmsingle['typec']['betasmd'].reshape(136,136,80,152)\n",
    "models['fithrf_glmdenoise_rr'] = results_glmsingle['typed']['betasmd'].reshape(136,136,80,152)\n",
    "\n",
    "# finally, let's compute split-half reliability. we are going to loop\n",
    "# through our 4 models and calculate split-half reliability for each of them\n",
    "\n",
    "vox_reliabilities = [] # output variable for reliability values\n",
    "\n",
    "modelnames = list(models.keys())\n",
    "\n",
    "# for each beta version...\n",
    "for m in range(len(modelnames)):\n",
    "    \n",
    "    print(f'computing reliability for beta version: {modelnames[m]}')\n",
    "    time.sleep(1)\n",
    "    \n",
    "    # get the repeated-condition GLM betas using our repindices variable\n",
    "    betas = models[modelnames[m]][:,:,:,repindices] # automatically reshapes to (X x Y x Z x 2 x nConditions)\n",
    "    x,y,z = betas.shape[:3] \n",
    "    \n",
    "    rels = np.full((x,y,z),np.nan)\n",
    "    \n",
    "    # loop through voxels in the 3D volume...\n",
    "    for xx in tqdm(range(x)):\n",
    "        for yy in range(y):\n",
    "            for zz in range(z):\n",
    "                \n",
    "                # reliability at a given voxel is pearson correlation between response profiles from first and \n",
    "                # second image presentations (dim = 25 repeated conditions)\n",
    "                rels[xx,yy,zz] = np.corrcoef(betas[xx,yy,zz,0],\n",
    "                                             betas[xx,yy,zz,1])[1,0]\n",
    "          \n",
    "    vox_reliabilities.append(rels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16cba872-53ae-4a83-99c2-2842c9aba7a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read mask image\n",
    "\n",
    "mask_folder = op.join(base_folder, '01_MRI', 'ANTS_REG', 'ROIS', subj)\n",
    "mask_file = 'C-mask_' + subj + '_right_CA3DG-To-meanFunc.nii.gz'\n",
    "fname = op.join(mask_folder, mask_file)\n",
    "img = nib.load(fname)\n",
    "roi = img.get_fdata()\n",
    "\n",
    "r_ca3dg = roi.astype(float)\n",
    "\n",
    "# convert voxels outside ROI to nan for overlay plotting\n",
    "r_ca3dg[r_ca3dg==0] = np.nan \n",
    "\n",
    "# get mean fMRI volume from run 1\n",
    "xyzt = (136,136,80,250)\n",
    "print(xyzt)\n",
    "meanvol = np.mean(data[0].reshape(xyzt),axis=3)\n",
    "\n",
    "# plot ROI on top of overlay\n",
    "plt.figure(figsize=(12,6))\n",
    "plt.imshow(meanvol[:,63,:],cmap='gray')\n",
    "plt.imshow(r_ca3dg[:,63,:],cmap='Blues',clim=(0,2))\n",
    "\n",
    "plt.title('voxels in nsdgeneral ROI')\n",
    "plt.box(False)\n",
    "plt.axis(False);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bdf2fda-a7ff-4fe8-b733-3d48c7049e34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for each GLM we will calculate median reliability for voxels within the\n",
    "# nsdgeneral visual ROI and compare using a bar graph\n",
    "\n",
    "comparison = []\n",
    "for vr in vox_reliabilities:\n",
    "    comparison.append(np.nanmedian(vr))\n",
    "   \n",
    "\n",
    "plt.figure(figsize=(18,6))\n",
    "plt.subplot(121)\n",
    "plt.bar(np.arange(len(comparison)),comparison,width=0.5)\n",
    "plt.title('Median voxel split-half reliability of GLM models')\n",
    "plt.xticks(np.arange(len(comparison)),np.array(['FITHRF', 'FITHRF\\nGLMDENOISE', 'FITHRF\\nGLMDENOISE\\nRR']));\n",
    "plt.ylim([-0.1,0.3])\n",
    "\n",
    "# draw plot showing the change in reliability between the baseline GLM\n",
    "# and the final output of GLMsingle (fithrf-glmdenoise-RR betas)\n",
    "vox_improvement = np.squeeze(vox_reliabilities[-1] - vox_reliabilities[0])\n",
    "#vox_improvement[r_prc != 1] = np.nan\n",
    "\n",
    "# get mean fMRI volume from run 1\n",
    "xyzt = (136,136,80,250)\n",
    "print(xyzt)\n",
    "meanvol = np.mean(data[0].reshape(xyzt),axis=3)\n",
    "\n",
    "plt.subplot(122)\n",
    "plt.imshow(meanvol[:,:,24],cmap='gray',aspect='auto')\n",
    "plt.imshow(vox_improvement[:,:,24],cmap='RdBu_r',clim=(-0.3,0.3),aspect='auto')\n",
    "plt.colorbar()\n",
    "plt.title('change in nsdgeneral voxel reliability**\\ndue to GLMsingle (r)')\n",
    "plt.xticks([])\n",
    "plt.yticks([])\n",
    "plt.xlabel('\\n**plotting (FITHRF_GLMDENOISE_RR - ASSUMEHRF) reliabilities');\n",
    "\n",
    "# notice that there is systematic increase in reliability moving from the\n",
    "# first to the second to the third to the final fourth version of the GLM\n",
    "# results. these increases reflect, respectively, the addition of HRF\n",
    "# fitting, the derivation and use of data-driven nuisance regressors, and\n",
    "# the use of ridge regression as a way to regularize the instability of\n",
    "# closely spaced experimental trials. depending on one's experimental\n",
    "# goals, it is possible with setting of option flags to activate a subset\n",
    "# of these analysis features.\n",
    "\n",
    "# also, keep in mind that in the above figure, we are simply showing the\n",
    "# median as a metric of the central tendency (you may want to peruse\n",
    "# individual voxels in scatter plots, for example)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b99da894-f2bb-40c1-9ef2-2805dc24b69c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(vox_reliabilities[0].reshape(-1),25,alpha=0.6,color='tomato');\n",
    "plt.hist(vox_reliabilities[1].reshape(-1),25,alpha=0.6,color='dodgerblue');\n",
    "plt.hist(vox_reliabilities[2].reshape(-1),25,alpha=0.6,color='limegreen');\n",
    "plt.xlabel('reliability (r)')\n",
    "plt.ylabel('# voxels')\n",
    "plt.legend(['FITHRF', 'FITHRF_GLMDENOISE', 'FITHRF_GLMDENOISE_RR'])\n",
    "plt.title('Change in distribution of voxel reliabilities');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d2e2d75-5091-450e-9b66-8571d8e46066",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(18,6))\n",
    "plt.subplot(131)\n",
    "plt.imshow(vox_reliabilities[0][:,:,9],cmap='RdBu_r',clim=(-0.3,0.3),aspect='auto', vmin=-0.4,vmax=0.4)\n",
    "plt.title('Voxel reliabilities with FITHRF', fontsize=10)\n",
    "plt.subplot(132)\n",
    "plt.imshow(vox_reliabilities[1][:,:,9],cmap='RdBu_r',clim=(-0.3,0.3),aspect='auto', vmin=-0.4,vmax=0.4)\n",
    "plt.title('Voxel reliabilities with FITHRF_GLMDENOISE', fontsize=10)\n",
    "plt.subplot(133)\n",
    "plt.imshow(vox_reliabilities[2][:,:,9],cmap='RdBu_r',clim=(-0.3,0.3),aspect='auto', vmin=-0.4,vmax=0.4)\n",
    "plt.title('Voxel reliabilities with FITHRF_GLMDENOISE_RR', fontsize=10)\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f184a3c-2ad0-41f6-8ad1-235583a16cc0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
