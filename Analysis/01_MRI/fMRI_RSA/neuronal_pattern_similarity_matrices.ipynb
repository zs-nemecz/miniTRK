{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "33f5ae44-91c6-4bcd-b0bc-b5b2b1897d07",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nibabel as nib\n",
    "import numpy as np\n",
    "import scipy.stats as spc\n",
    "import scipy.io as sio\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import os\n",
    "import os.path as op\n",
    "import time\n",
    "import urllib.request\n",
    "from tqdm import tqdm # progress bars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "50919e41-fec7-4448-8ab8-48f32a32af3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_vox_reliabilities(repindices, results_glmsingle, subj, output_folder):\n",
    "    \n",
    "    models = dict()\n",
    "    models['fithrf_glmdenoise'] = results_glmsingle['typec']['betasmd'].reshape(136,136,80,152)\n",
    "    models['fithrf_glmdenoise_rr'] = results_glmsingle['typed']['betasmd'].reshape(136,136,80,152)\n",
    "\n",
    "    out_fname = op.join(output_folder, 'vox_reliabilities_' + subj + '.npy')\n",
    "    vox_reliabilities = [] # output variable for reliability values\n",
    "\n",
    "    if not op.exists(out_fname):\n",
    "\n",
    "        modelnames = list(models.keys())\n",
    "\n",
    "        # for each beta version...\n",
    "        for m in range(len(modelnames)):\n",
    "\n",
    "            print(f'computing reliability for beta version: {modelnames[m]}')\n",
    "            time.sleep(1)\n",
    "\n",
    "            # get the repeated-condition GLM betas using our repindices variable\n",
    "            betas = models[modelnames[m]][:,:,:,repindices] # automatically reshapes to (X x Y x Z x 2 x nConditions)\n",
    "            x,y,z = betas.shape[:3] \n",
    "\n",
    "            rels = np.full((x,y,z),np.nan)\n",
    "\n",
    "            # loop through voxels in the 3D volume...\n",
    "            for xx in tqdm(range(x)):\n",
    "                for yy in range(y):\n",
    "                    for zz in range(z):\n",
    "\n",
    "                        # reliability at a given voxel is pearson correlation between response profiles from first and \n",
    "                        # second image presentations (dim = 25 repeated conditions)\n",
    "                        rels[xx,yy,zz] = np.corrcoef(betas[xx,yy,zz,0],\n",
    "                                                     betas[xx,yy,zz,1])[1,0]\n",
    "\n",
    "            vox_reliabilities.append(rels)\n",
    "\n",
    "        vox_reliabilities = np.array(vox_reliabilities)\n",
    "        \n",
    "        np.save(out_fname, vox_reliabilities)\n",
    "\n",
    "    else:\n",
    "        vox_reliabilities = np.load(out_fname)\n",
    "        \n",
    "    return vox_reliabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0bed48f8-4c94-4915-8236-4e50dc1a6d67",
   "metadata": {},
   "outputs": [],
   "source": [
    "def condition_info(designAll):\n",
    "    # construct a vector containing 0-indexed condition numbers in chronological order\n",
    "    corder = []\n",
    "    for p in range(designALL.shape[0]):\n",
    "        if np.any(designALL[p]):\n",
    "            corder.append(np.argwhere(designALL[p])[0,0])\n",
    "\n",
    "    corder = np.array(corder)\n",
    "\n",
    "    # in order to compute split-half reliability, we have to do some indexing.\n",
    "    # we want to find images with least two repetitions and then prepare a\n",
    "    # useful matrix of indices that refer to when these occur.\n",
    "\n",
    "    repindices = [] # 2 x images containing stimulus trial indices.\n",
    "\n",
    "    # the first row refers to the first presentation; the second row refers to\n",
    "    # the second presentation.\n",
    "    for p in range(designALL.shape[1]): # loop over every condition\n",
    "\n",
    "        temp = np.argwhere(corder==p)[:,0] # find indices where this condition was shown in the condition order\n",
    "\n",
    "        # note that for conditions with 3 presentations, we are simply ignoring the third trial\n",
    "        if len(temp) >= 2:\n",
    "            repindices.append([temp[0], temp[1]]) \n",
    "\n",
    "    repindices = np.vstack(np.array(repindices)).T \n",
    "    \n",
    "    images = [str(j+1) + k for j in range(181) for k in 'abc']\n",
    "    lureindices = [] # 2 x images containing stimulus trial indices.\n",
    "    lures = []\n",
    "\n",
    "    # the first row refers to the first presentation; the second row refers to\n",
    "    # the second presentation.\n",
    "    for i, im in enumerate(images): # loop over every condition\n",
    "        temp = []\n",
    "\n",
    "        temp = np.argwhere(corder==i)[:,0] # find indices where this condition was shown\n",
    "\n",
    "        if len(temp) == 1: # check if this exact image was shown only once (otherwise it's a repeat)\n",
    "            image_version = im[-1]\n",
    "\n",
    "            lureindices.append(temp[0])\n",
    "            lures.append(im)\n",
    "\n",
    "    lureindices = np.array(lureindices).reshape(48,2).T\n",
    "    lures = np.array(lures).reshape(48,2).T\n",
    "    \n",
    "    return corder, repindices, lureindices, lures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1e383985-6b99-4307-9824-33871d00300f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def neuronal_pattern_sim_mat(betas, mask, vox_rel, out_fname, thr=-2):\n",
    "    \n",
    "    print(f'vox rel min {np.nanmax(vox_rel)}')\n",
    "    # get betas from within mask\n",
    "    betas_thr = betas.reshape(136,136,80,152)[((mask==1) & (vox_rel > thr)), :].T\n",
    "    print(f'Thresholded betas shape: {betas_thr.shape}')\n",
    "    \n",
    "    # condition-wise similarity matrix\n",
    "    corr_thr = np.corrcoef(betas_thr)\n",
    "    print(f'Corr mat shape: {betas_thr.shape}')\n",
    "    \n",
    "    if corr_thr.shape[0]!=152:\n",
    "        print(f'Error: Number of rows \\({corr_rr_thr.shape[0]}\\) does not match expected number of conditions')\n",
    "    else: \n",
    "        np.save(out_fname, corr_thr)\n",
    "        return corr_thr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ae15067d-5512-4f70-abcf-04a9e9534a16",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sim_bins(lures, ratings):\n",
    "    sim_bins = []\n",
    "\n",
    "    for img1, img2 in zip(lures[0], lures[1]):\n",
    "\n",
    "        img1_type = img1[:-1]\n",
    "        img1_ver = img1[-1]\n",
    "\n",
    "        img2_type = img2[:-1]\n",
    "        img2_ver = img2[-1]\n",
    "\n",
    "        if img1_type != img2_type:\n",
    "            print('Error: types don\\'t match')\n",
    "\n",
    "        abc = img1_ver + img2_ver\n",
    "        #print(img1_type, abc)\n",
    "\n",
    "        sim_bin = ratings['Rating_Bins'].loc[(ratings['ImageType'] == int(img1_type)) & (ratings['abc'] == abc)].reset_index(drop=True)[0]\n",
    "\n",
    "        #print(sim_bin)\n",
    "        sim_bins.append(sim_bin)\n",
    "    \n",
    "    target_bins = ['target'] * 25\n",
    "    sim_bins = sim_bins + target_bins \n",
    "    \n",
    "    return sim_bins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aba1bcb4-00d2-4e52-ad98-5fe2c6c9715d",
   "metadata": {},
   "outputs": [],
   "source": [
    "similarity_path =  op.join('C:\\\\', 'Users','Zsuzsa', 'Documents', 'miniTRK', 'Data', 'SimilarityRating')\n",
    "ratings_fname = op.join(similarity_path, 'SimilarityRating_FinalSample.csv')\n",
    "ratings = pd.read_csv(ratings_fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0c08de1e-4eae-4a83-a22a-335eca6b4181",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['760384']\n"
     ]
    }
   ],
   "source": [
    "base_folder = op.join('D:\\\\', 'Zsuzsa', 'HCCCL', 'miniTRK', 'Results')\n",
    "design_folder = op.join(base_folder, '02_APS_MRI_Logs', 'single_trials')\n",
    "out_path = op.join(base_folder,'01_MRI','fMRI_RSA', 'BetaCorrMats')\n",
    "#subjects = np.loadtxt('test_subjects.txt', dtype=str)\n",
    "subjects = ['760384']\n",
    "print(subjects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ef6ce656-eaf0-42df-9f85-dc95bca1847e",
   "metadata": {},
   "outputs": [],
   "source": [
    "task = 'OBJ'\n",
    "acq = 'ENC'\n",
    "stimdur = 3.0\n",
    "tr = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b4f878d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "760384\n",
      "[[122  78  60  11  71 137  18  79  13 104  29   2  49  36   0  97  91 139\n",
      "   21 128 116  63   4 127 106]\n",
      " [126  85  64  16  74 140  25  86  17 110  31   8  56  42   7  99  96 142\n",
      "   23 133 121  65  20 131 109]]\n",
      "loading existing GLMsingle outputs from directory:\n",
      "\tD:\\Zsuzsa\\HCCCL\\miniTRK\\Results\\01_MRI\\fMRI_RSA\\GLMsingle\\760384\\OBJ_ENC\n"
     ]
    }
   ],
   "source": [
    "frames = []\n",
    "for subj in subjects:\n",
    "    \n",
    "    print(subj)\n",
    "    mask_folder = op.join(base_folder, '01_MRI', 'ANTS_REG', 'ROIS', subj)\n",
    "    designs = []\n",
    "    \n",
    "    # load designs\n",
    "    for r in ['1','2']:\n",
    "        design_file =  subj + '_' + task + '_SingleTrials_run_' + r + '_Upsampled.csv' \n",
    "        fname = op.join(design_folder, design_file)\n",
    "        design = pd.read_csv(fname).to_numpy()\n",
    "        designs.append(design)\n",
    "        \n",
    "    # consolidate design matrices\n",
    "    designALL = np.concatenate(designs,axis=0)\n",
    "\n",
    "    corder, repindices, lureindices, lures = condition_info(designALL)\n",
    "    print(repindices)\n",
    "    \n",
    "    # load GLMsingle outputs (only type C and type D)\n",
    "    outputdir_glmsingle = op.join(base_folder,'01_MRI','fMRI_RSA','GLMsingle', subj, task + '_' + acq)\n",
    "    \n",
    "    # load existing file outputs if they exist\n",
    "    results_glmsingle = dict()\n",
    "    \n",
    "    if not op.exists(outputdir_glmsingle):\n",
    "\n",
    "        print('No GLMsingle output. Please run GLMsingle')\n",
    "\n",
    "    else:\n",
    "        print(f'loading existing GLMsingle outputs from directory:\\n\\t{outputdir_glmsingle}')\n",
    "        \n",
    "        results_glmsingle['typea'] = np.load(op.join(outputdir_glmsingle,'TYPEA_ONOFF.npy'),allow_pickle=True).item()\n",
    "        results_glmsingle['typec'] = np.load(op.join(outputdir_glmsingle,'TYPEC_FITHRF_GLMDENOISE.npy'),allow_pickle=True).item()\n",
    "        results_glmsingle['typed'] = np.load(op.join(outputdir_glmsingle,'TYPED_FITHRF_GLMDENOISE_RR.npy'),allow_pickle=True).item()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8f03e98a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.4431019 , -0.33924586, -1.2115256 , -0.45679832,  1.176322  ,\n",
       "       -0.9310342 ,  0.37455937,  1.0106702 , -1.0097609 ,  3.611507  ,\n",
       "       -0.06361842,  3.4416943 ,  1.1861079 ,  2.024457  , -3.9822187 ,\n",
       "       -3.553678  , -0.60248065, -0.05945471, -2.6391644 , -0.5704894 ,\n",
       "       -1.9350622 ,  0.8514701 ,  1.519816  , -2.327885  , -2.719463  ,\n",
       "       -3.062109  , -0.9431678 ,  0.92221546,  1.9906017 , -0.84569633,\n",
       "       -1.0204957 ,  4.2035832 ,  2.3697858 ,  1.5256041 , -1.0744642 ,\n",
       "        0.76115036,  3.9610102 ,  1.0791007 , -0.03571042, -3.0276864 ,\n",
       "       -5.86808   , -0.4654776 ,  0.7162816 , -1.2108122 ,  0.6977863 ,\n",
       "        0.13026191,  1.3412912 ,  2.2844217 ,  2.9267282 , -1.2492111 ,\n",
       "        0.18719688,  0.40718335, -0.5638015 ,  0.52235055, -3.42464   ,\n",
       "        0.46384534,  1.0185826 , -2.0684748 , -1.4357524 ,  0.07018877,\n",
       "        3.9480646 , -0.6862677 , -2.488529  , -1.0600749 , -1.6876966 ,\n",
       "       -1.1470199 , -1.1901504 , -0.393207  ,  0.49962905, -0.9826624 ,\n",
       "        2.0009153 ,  1.618747  ,  3.050716  , -0.4078456 , -2.4559119 ,\n",
       "       -2.320634  , -3.2478023 ,  2.3250265 ,  2.6862335 , -0.59695923,\n",
       "       -0.73634726,  1.6030904 , -0.63679636, -3.1659803 , -1.668955  ,\n",
       "       -2.6586576 ,  0.92693025, -0.09436717,  1.1876571 ,  2.3753865 ,\n",
       "        1.9946697 , -1.5911832 , -1.6938246 , -0.79900837,  0.27812558,\n",
       "        0.44666165,  2.1085522 ,  0.23407403, -0.19950625, -1.4471978 ,\n",
       "       -1.4123033 ,  0.22439916, -1.5754007 , -2.8020785 , -1.3301722 ,\n",
       "        0.1516076 , -0.05806424, -0.2252239 , -1.0997977 ,  0.00767573,\n",
       "       -0.15722694,  0.88123345, -2.7012386 , -2.5631447 , -1.4641771 ,\n",
       "       -0.20777698,  2.2852194 ,  2.9840465 ,  3.3613575 ,  3.8578722 ,\n",
       "        0.50800616,  1.4075367 , -0.9636684 , -0.940598  ,  0.01776864,\n",
       "        0.6254291 , -0.8201064 ,  0.5507184 , -0.425869  ,  0.89038795,\n",
       "       -1.8114024 ,  0.09671013, -2.4070134 , -1.7342471 , -1.1793759 ,\n",
       "       -2.0051963 ,  1.2395666 , -1.047944  ,  1.4598012 , -1.1818701 ,\n",
       "        0.24566092,  3.0757985 ,  0.01297215, -1.669204  , -2.4573154 ,\n",
       "        1.0804461 ,  0.3990104 , -0.6367366 ,  0.48711687,  0.23634124,\n",
       "        1.1512253 ,  0.15538704], dtype=float32)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_glmsingle['typed']['betasmd'][50,50,50,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f484e0d0-616e-4b33-9b22-9f96018413c2",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "760384\n",
      "[[122  78  60  11  71 137  18  79  13 104  29   2  49  36   0  97  91 139\n",
      "   21 128 116  63   4 127 106]\n",
      " [126  85  64  16  74 140  25  86  17 110  31   8  56  42   7  99  96 142\n",
      "   23 133 121  65  20 131 109]]\n",
      "loading existing GLMsingle outputs from directory:\n",
      "\tD:\\Zsuzsa\\HCCCL\\miniTRK\\Results\\01_MRI\\fMRI_RSA\\GLMsingle\\760384\\OBJ_ENC\n",
      "[ 0.28081076  0.19016633 -0.10525645 -0.04813297 -0.04973302 -0.25629422\n",
      " -0.27404128  0.04710536 -0.15646467 -0.04261089  0.30474282 -0.23187092\n",
      "  0.08797818 -0.21383761 -0.21274008 -0.1369628  -0.13465936  0.25328215\n",
      "  0.09322416 -0.15121395 -0.20933228 -0.1649299   0.26592724 -0.19431238\n",
      " -0.08317897  0.09186536 -0.07015201 -0.40321449  0.00979905  0.01150918\n",
      " -0.339011   -0.1591746  -0.18522193 -0.14400895  0.55905799 -0.07509759\n",
      " -0.14468919  0.01837774  0.03889038 -0.14278559 -0.24180377  0.08375235\n",
      " -0.21028552  0.09525798  0.00499684 -0.07478319 -0.5391845  -0.26367105\n",
      "  0.06347869 -0.05050093 -0.18558096  0.08616631  0.07773692 -0.22639996\n",
      " -0.1824784   0.23219438 -0.28798617 -0.14638562 -0.0738235   0.15737974\n",
      "  0.1102011   0.25897745  0.06735262  0.03244844 -0.08503401  0.3387807\n",
      "  0.17437518  0.04193375  0.32844012 -0.09683276  0.41556938 -0.24303135\n",
      "  0.14725744         nan         nan         nan         nan         nan\n",
      "         nan         nan]\n",
      "left\n",
      "CA3DG\n",
      "mask sum: 153.0\n",
      "vox rel min 0.8404014617025067\n",
      "Thresholded betas shape: (152, 0)\n",
      "Corr mat shape: (152, 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Zsuzsa\\anaconda3\\lib\\site-packages\\numpy\\lib\\function_base.py:495: RuntimeWarning: Mean of empty slice.\n",
      "  avg = a.mean(axis)\n",
      "C:\\Users\\Zsuzsa\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:181: RuntimeWarning: invalid value encountered in true_divide\n",
      "  ret = um.true_divide(\n",
      "C:\\Users\\Zsuzsa\\anaconda3\\lib\\site-packages\\numpy\\lib\\function_base.py:2821: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  c = cov(x, y, rowvar, dtype=dtype)\n",
      "C:\\Users\\Zsuzsa\\anaconda3\\lib\\site-packages\\numpy\\lib\\function_base.py:2680: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  c *= np.true_divide(1, fact)\n",
      "C:\\Users\\Zsuzsa\\anaconda3\\lib\\site-packages\\numpy\\lib\\function_base.py:2680: RuntimeWarning: invalid value encountered in multiply\n",
      "  c *= np.true_divide(1, fact)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vox rel min 0.8404014617025067\n",
      "Thresholded betas shape: (152, 0)\n",
      "Corr mat shape: (152, 0)\n",
      "(2,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Zsuzsa\\AppData\\Local\\Temp\\ipykernel_19164\\2370200159.py:75: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  data = np.array([np.concatenate((lure_pattern_sim, lure_pattern_sim_thr)),\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Shape of passed values is (2, 1), indices imply (2, 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_19164\\2370200159.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     76\u001b[0m                              np.concatenate((rep_pattern_sim, rep_pattern_sim_thr))]).T\n\u001b[0;32m     77\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 78\u001b[1;33m             \u001b[0msim_frame\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'PatternSim'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'PatternSim_THR'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     79\u001b[0m             \u001b[0msim_frame\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Rating_Bins'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msim_bins\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     80\u001b[0m             \u001b[0msim_frame\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'ID'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msubj\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[0;32m    692\u001b[0m                 )\n\u001b[0;32m    693\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 694\u001b[1;33m                 mgr = ndarray_to_mgr(\n\u001b[0m\u001b[0;32m    695\u001b[0m                     \u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    696\u001b[0m                     \u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\internals\\construction.py\u001b[0m in \u001b[0;36mndarray_to_mgr\u001b[1;34m(values, index, columns, dtype, copy, typ)\u001b[0m\n\u001b[0;32m    349\u001b[0m     )\n\u001b[0;32m    350\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 351\u001b[1;33m     \u001b[0m_check_values_indices_shape_match\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    352\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    353\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mtyp\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"array\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\internals\\construction.py\u001b[0m in \u001b[0;36m_check_values_indices_shape_match\u001b[1;34m(values, index, columns)\u001b[0m\n\u001b[0;32m    420\u001b[0m         \u001b[0mpassed\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    421\u001b[0m         \u001b[0mimplied\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 422\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"Shape of passed values is {passed}, indices imply {implied}\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    423\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    424\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Shape of passed values is (2, 1), indices imply (2, 2)"
     ]
    }
   ],
   "source": [
    "frames = []\n",
    "for subj in subjects:\n",
    "    \n",
    "    print(subj)\n",
    "    mask_folder = op.join(base_folder, '01_MRI', 'ANTS_REG', 'ROIS', subj)\n",
    "    designs = []\n",
    "    \n",
    "    # load designs\n",
    "    for r in ['1','2']:\n",
    "        design_file =  subj + '_' + task + '_SingleTrials_run_' + r + '_Upsampled.csv' \n",
    "        fname = op.join(design_folder, design_file)\n",
    "        design = pd.read_csv(fname).to_numpy()\n",
    "        designs.append(design)\n",
    "        \n",
    "    # consolidate design matrices\n",
    "    designALL = np.concatenate(designs,axis=0)\n",
    "\n",
    "    corder, repindices, lureindices, lures = condition_info(designALL)\n",
    "    print(repindices)\n",
    "    \n",
    "    # load GLMsingle outputs (only type C and type D)\n",
    "    outputdir_glmsingle = op.join(base_folder,'01_MRI','fMRI_RSA','GLMsingle', subj, task + '_' + acq)\n",
    "    \n",
    "    # load existing file outputs if they exist\n",
    "    results_glmsingle = dict()\n",
    "    \n",
    "    if not op.exists(outputdir_glmsingle):\n",
    "\n",
    "        print('No GLMsingle output. Please run GLMsingle')\n",
    "\n",
    "    else:\n",
    "        print(f'loading existing GLMsingle outputs from directory:\\n\\t{outputdir_glmsingle}')\n",
    "        \n",
    "        results_glmsingle['typec'] = np.load(op.join(outputdir_glmsingle,'TYPEC_FITHRF_GLMDENOISE.npy'),allow_pickle=True).item()\n",
    "        results_glmsingle['typed'] = np.load(op.join(outputdir_glmsingle,'TYPED_FITHRF_GLMDENOISE_RR.npy'),allow_pickle=True).item()\n",
    "\n",
    "    rel_output_folder = op.join(base_folder,'01_MRI','fMRI_RSA', 'vox_reliabilities')\n",
    "    vox_reliabilities = calc_vox_reliabilities(repindices, results_glmsingle, subj, rel_output_folder)\n",
    "    \n",
    "    print(vox_reliabilities[1,50,50,:])\n",
    "    \n",
    "    for hemi in ['left', 'right']:\n",
    "        \n",
    "        print(hemi)\n",
    "        \n",
    "        for area in ['CA3DG', 'CA1', 'ERC', 'SUB', 'PHC', 'PRC']:\n",
    "            \n",
    "            print(area)\n",
    "            \n",
    "            mask_file = 'C-mask_' + subj + '_' + hemi + '_' + area + '-To-meanFunc.nii.gz'\n",
    "            fname = op.join(mask_folder, mask_file)\n",
    "            img = nib.load(fname)\n",
    "            mask = img.get_fdata()\n",
    "            \n",
    "            mask = mask.astype(float)\n",
    "            print(f'mask sum: {mask.sum()}')\n",
    "\n",
    "            # convert voxels outside ROI to nan for overlay plotting\n",
    "            mask[mask>0.1] = np.nan \n",
    "            \n",
    "            out_fname = op.join(out_path, subj + '_' + hemi + '_' + area + '_RR.npy')\n",
    "            corr_rr = neuronal_pattern_sim_mat(results_glmsingle['typed']['betasmd'], mask, vox_reliabilities[1], out_fname)\n",
    "            corr_rr_thr = neuronal_pattern_sim_mat(results_glmsingle['typed']['betasmd'], mask, vox_reliabilities[1], out_fname, thr=0.0)\n",
    "            \n",
    "            # Lure Similarity\n",
    "            lure_pattern_sim = corr_rr[lureindices[0], lureindices[1]]\n",
    "            lure_pattern_sim_thr = corr_rr_thr[lureindices[0], lureindices[1]]\n",
    "            \n",
    "            # Repetition Similarity\n",
    "            rep_pattern_sim = corr_rr[repindices[0], repindices[1]]\n",
    "            rep_pattern_sim_thr = corr_rr_thr[repindices[0], repindices[1]]\n",
    "            \n",
    "            sim_bins = get_sim_bins(lures, ratings)\n",
    "            \n",
    "            data = np.array([np.concatenate((lure_pattern_sim, lure_pattern_sim_thr)),\n",
    "                             np.concatenate((rep_pattern_sim, rep_pattern_sim_thr))]).T\n",
    "            print(data.shape)\n",
    "            sim_frame = pd.DataFrame(data=data, columns=['PatternSim', 'PatternSim_THR'])\n",
    "            sim_frame['Rating_Bins'] = sim_bins\n",
    "            sim_frame['ID'] = subj\n",
    "            sim_frame['Hemi'] = hemi\n",
    "            sim_frame['Area'] = area\n",
    "            sim_frame['Mask'] = hemi + '_' + area\n",
    "            \n",
    "            frames.append(sim_frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea8a198e-b1ad-4e11-a763-9a2a024e8f92",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = np.load(op.join(outputdir_glmsingle,'TYPEC_FITHRF_GLMDENOISE.npy'),allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "865134f5-d31b-4539-9fb4-6a5d0a5ec600",
   "metadata": {},
   "outputs": [],
   "source": [
    "op.exists(op.join(outputdir_glmsingle,'TYPEC_FITHRF_GLMDENOISE.npy'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8da7e95a-0a2c-4a58-884f-fbb7ae386383",
   "metadata": {},
   "outputs": [],
   "source": [
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7db132c-2629-4abc-bed0-9aae23791414",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
